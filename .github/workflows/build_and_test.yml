#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#

name: Build and test

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:
  license-check:
    name: "License Check"
    runs-on: ubuntu-latest
    timeout-minutes: 20
    steps:
      - name: Checkout repository
        uses: actions/checkout@v5
      - name: Check license header
        uses: apache/skywalking-eyes@main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          config: .github/.licenserc.yaml

  build-macos-15-swift60:
    runs-on: macos-15
    timeout-minutes: 20
    steps:
    - uses: actions/checkout@v5
    - uses: swift-actions/setup-swift@d10500c1ac8822132eebbd74c48c3372c71d7ff5
      with:
        swift-version: "6.0"
    - name: Build
      run: swift build -c release

  build-macos-15-swift61:
    runs-on: macos-15
    timeout-minutes: 20
    steps:
    - uses: actions/checkout@v5
    - name: Build
      run: swift build -c release

  build-macos-26-swift62:
    runs-on: macos-26
    timeout-minutes: 20
    steps:
    - uses: actions/checkout@v5
    - name: Build
      run: swift build -c release

  build-ubuntu-latest:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    steps:
    - uses: actions/checkout@v5
    - name: Build
      run: |
        docker run swift:6.2 uname -a
        docker run -v $PWD:/spark -w /spark swift:6.2 swift build -c release

  build-ubuntu-arm:
    runs-on: ubuntu-24.04-arm
    timeout-minutes: 20
    steps:
    - uses: actions/checkout@v5
    - name: Build
      run: |
        docker run swift:6.2 uname -a
        docker run -v $PWD:/spark -w /spark swift:6.2 swift build -c release

  integration-test-ubuntu:
    runs-on: ubuntu-latest
    env:
      SPARK_REMOTE: "sc://localhost:15003"
    services:
      spark:
        image: apache/spark:4.0.1
        env:
          SPARK_NO_DAEMONIZE: 1
        ports:
          - 15003:15002
        options: --entrypoint /opt/spark/sbin/start-connect-server.sh
    steps:
    - uses: actions/checkout@v5
    - name: Build
      run: |
        docker run swift:6.2 uname -a
        docker run --add-host=host.docker.internal:host-gateway -v $PWD:/spark -w /spark -e SPARK_REMOTE='sc://host.docker.internal:15003' swift:6.2 swift test --no-parallel -c release

  integration-test-ubuntu-spark41:
    runs-on: ubuntu-latest
    env:
      SPARK_REMOTE: "sc://localhost:15003"
    services:
      spark:
        image: apache/spark:4.1.0-preview2
        env:
          SPARK_NO_DAEMONIZE: 1
        ports:
          - 15003:15002
        options: --entrypoint /opt/spark/sbin/start-connect-server.sh
    steps:
    - uses: actions/checkout@v5
    - name: Build
      run: |
        docker run swift:6.2 uname -a
        docker run --add-host=host.docker.internal:host-gateway -v $PWD:/spark -w /spark -e SPARK_REMOTE='sc://host.docker.internal:15003' swift:6.2 swift test --no-parallel -c release

  integration-test-mac-spark41:
    runs-on: macos-15
    timeout-minutes: 20
    env:
      SPARK_LOCAL_IP: localhost
    steps:
    - uses: actions/checkout@v5
    - name: Build
      run: swift test --filter NOTHING -c release
    - name: Test
      run: |
        curl -LO https://dist.apache.org/repos/dist/dev/spark/v4.1.0-preview3-rc1-bin/spark-4.1.0-preview3-bin-hadoop3.tgz
        tar xvfz spark-4.1.0-preview3-bin-hadoop3.tgz && rm spark-4.1.0-preview3-bin-hadoop3.tgz
        mv spark-4.1.0-preview3-bin-hadoop3 /tmp/spark
        cd /tmp/spark/sbin
        ./start-connect-server.sh
        cd -
        swift test --no-parallel -c release

  integration-test-mac:
    runs-on: macos-15
    timeout-minutes: 20
    env:
      SPARK_LOCAL_IP: localhost
    steps:
    - uses: actions/checkout@v5
    - name: Build
      run: swift test --filter NOTHING -c release
    - name: Test
      run: |
        curl -LO https://www.apache.org/dyn/closer.lua/spark/spark-4.0.1/spark-4.0.1-bin-hadoop3.tgz?action=download
        tar xvfz spark-4.0.1-bin-hadoop3.tgz && rm spark-4.0.1-bin-hadoop3.tgz
        mv spark-4.0.1-bin-hadoop3 /tmp/spark
        cd /tmp/spark/sbin
        ./start-connect-server.sh
        cd -
        swift test --no-parallel -c release

  integration-test-token:
    runs-on: macos-15
    timeout-minutes: 20
    env:
      SPARK_LOCAL_IP: localhost
      SPARK_CONNECT_AUTHENTICATE_TOKEN: ${{ github.run_id }}-${{ github.run_attempt }}
    steps:
    - uses: actions/checkout@v5
    - name: Build
      run: swift test --filter NOTHING -c release
    - name: Test
      run: |
        curl -LO https://dist.apache.org/repos/dist/dev/spark/v4.1.0-preview3-rc1-bin/spark-4.1.0-preview3-bin-hadoop3.tgz
        tar xvfz spark-4.1.0-preview3-bin-hadoop3.tgz && rm spark-4.1.0-preview3-bin-hadoop3.tgz
        mv spark-4.1.0-preview3-bin-hadoop3 /tmp/spark
        cd /tmp/spark/sbin
        ./start-connect-server.sh
        cd -
        swift test --no-parallel -c release

  integration-test-mac-spark3:
    runs-on: macos-15
    timeout-minutes: 20
    env:
      SPARK_LOCAL_IP: localhost
    steps:
    - uses: actions/checkout@v5
    - name: Install Java
      uses: actions/setup-java@v4
      with:
        distribution: zulu
        java-version: 17
    - name: Build
      run: swift test --filter NOTHING -c release
    - name: Test
      run: |
        curl -LO https://www.apache.org/dyn/closer.lua/spark/spark-3.5.7/spark-3.5.7-bin-hadoop3.tgz?action=download
        tar xvfz spark-3.5.7-bin-hadoop3.tgz && rm spark-3.5.7-bin-hadoop3.tgz
        mv spark-3.5.7-bin-hadoop3 /tmp/spark
        cd /tmp/spark/sbin
        ./start-connect-server.sh --packages org.apache.spark:spark-connect_2.12:3.5.7
        cd -
        swift test --no-parallel -c release

  integration-test-mac-spark3-iceberg:
    runs-on: macos-15
    timeout-minutes: 20
    env:
      SPARK_LOCAL_IP: localhost
      SPARK_ICEBERG_TEST_ENABLED: "true"
    steps:
    - uses: actions/checkout@v5
    - name: Install Java
      uses: actions/setup-java@v4
      with:
        distribution: zulu
        java-version: 17
    - name: Build
      run: swift test --filter NOTHING -c release
    - name: Test
      run: |
        curl -LO https://www.apache.org/dyn/closer.lua/spark/spark-3.5.7/spark-3.5.7-bin-hadoop3.tgz?action=download
        tar xvfz spark-3.5.7-bin-hadoop3.tgz && rm spark-3.5.7-bin-hadoop3.tgz
        mv spark-3.5.7-bin-hadoop3 /tmp/spark
        cd /tmp/spark/sbin
        ./start-connect-server.sh --packages org.apache.spark:spark-connect_2.12:3.5.7,org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.10.0 -c spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog -c spark.sql.catalog.local.type=hadoop -c spark.sql.catalog.local.warehouse=/tmp/spark/warehouse -c spark.sql.defaultCatalog=local
        cd -
        swift test --filter DataFrameWriterV2Tests -c release
        swift test --filter IcebergTest -c release

  integration-test-mac-spark4-iceberg:
    runs-on: macos-15
    timeout-minutes: 20
    env:
      SPARK_LOCAL_IP: localhost
      SPARK_ICEBERG_TEST_ENABLED: "true"
    steps:
    - uses: actions/checkout@v5
    - name: Install Java
      uses: actions/setup-java@v4
      with:
        distribution: zulu
        java-version: 17
    - name: Build
      run: swift test --filter NOTHING -c release
    - name: Test
      run: |
        curl -LO https://www.apache.org/dyn/closer.lua/spark/spark-4.0.1/spark-4.0.1-bin-hadoop3.tgz?action=download
        tar xvfz spark-4.0.1-bin-hadoop3.tgz && rm spark-4.0.1-bin-hadoop3.tgz
        mv spark-4.0.1-bin-hadoop3 /tmp/spark
        cd /tmp/spark/sbin
        ./start-connect-server.sh --packages org.apache.spark:spark-connect_2.13:4.0.1,org.apache.iceberg:iceberg-spark-runtime-4.0_2.13:1.10.0 -c spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog -c spark.sql.catalog.local.type=hadoop -c spark.sql.catalog.local.warehouse=/tmp/spark/warehouse -c spark.sql.defaultCatalog=local
        cd -
        swift test --filter DataFrameWriterV2Tests -c release
        swift test --filter IcebergTest -c release

  linter:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    steps:
    - name: Checkout repository
      uses: actions/checkout@v5
      with:
        fetch-depth: 0
    - name: Super-Linter
      uses: super-linter/super-linter@12150456a73e248bdc94d0794898f94e23127c88
      env:
        DEFAULT_BRANCH: main
        VALIDATE_MARKDOWN: true
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
